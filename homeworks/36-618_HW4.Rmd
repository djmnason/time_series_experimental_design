---
title: "36-618 HW4"
author: "Daniel Nason"
date: "3/18/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages_data, warning=FALSE, message=FALSE}
setwd("C:/Users/Owner/CMU/Spring/36-618/HW/HW4")
library(forecast)
library(astsa)
library(tidyverse)
```

## Question 1

### a)

```{r q1a_1}
urate <- UnempRate
tsdisplay(urate, main = "US monthly unemployment rate from 1948 to 2016")
monthplot(urate)
```

From the raw data we see that there is evidence seasonal cycles in the data. The monthplot shows that while there is constant variance across each of the months, there are cyclical fluctuations that suggest evidence of a seasonal cycle as well as a drift since the mean is not constant across each month. The ACF and PACF plots also show this since the ACF values slowly decay (suggesting a drift) and there are spikes in PACF values approximately around lags 12 and 22 (suggesting a seasonal cycle that is approximately annual).

```{r q1a_2}
tsdisplay(diff(urate), main ='Differenced US monthly unemployment rate from 1948 to 2016')
monthplot(diff(urate))
```

The plot of the differenced time series suggests that the differencing removed the trend, but the ACF and PACF plots show large values at around lags 10 and 20 which indicates that a seasonal cycle is still present in the data. The monthplot of the differenced time series shows evidence of a seasonal cycle based on the month of the year, and that the variance is not constant. 

```{r q1a_3}
tsdisplay(diff(urate, lag = 12), main = "Lag 12 differenced US monthly unemployment rate from 1948 to 2016")
monthplot(diff(urate, lag = 12))
```

The plot of the differenced time series at lag 12 suggests that the differencing removed the trend but there is still evidence of a seasonal cycle. The seasonal cycle also does not appear to have constant variance over time, such as the difference in the size of the spikes between 1960 and 1970 versus 2000 and 2010. The ACF plot suggests that an AR process is present by the exponential decay in ACF values, and and PACF plot has seasonal spikes around lags 11 and 21 in addition to the additional spikes at the first few lags, which suggests a seasonal cycle is present. The monthplot of the differenced time series at lag 12 appears to have relatively constant variance and a mean of 0 across each of the months.

Given the behavior in the ACF, PACF and monthplots, it would not make sense to model the differenced time series at lag 1 with a stationary time series process since there is evidence of a seasonal cycle. However, it would make sense to model the differenced time series at lag 12 with a stationary process since this differenced series has constant variance and mean of 0.

### b)

#### i)

```{r q1b_1}
auto.arima(urate, d = 1, D = 0, trace=T, approximation = F, allowdrift = F)
```

The order of the parameters identified is SARIMA$(4, 1, 4)(1, 0, 0)_{12}$.

```{r q1b_1_obs_fit}
q1bi_fit <- Arima(urate, order = c(4,1,4), seasonal = list(order=c(1,0,0), period = 12))
plot(urate,
     main = "Observations vs. fitted SARIMA(4,1,4)(1,0,0)[12] values",
     ylab = "Unemployment rate")
lines(urate-q1bi_fit$resid, col="red")
legend("topleft",legend = c("Actual", "Fitted"), fill = c("black", "red"))
```

Comparing the observations to the fitted values, we see that the fitted values fit the data extremely well and capture almost all of the fluctuations in the sample. This suggests that the model is a good fit for the data.

```{r q1b_1_resid}
plot(q1bi_fit$resid, main = "Fitted SARIMA(4,1,4)(1,0,0)[12] residual values", ylab = "Residual values")
acf(q1bi_fit$resid[1:length(q1bi_fit$residuals)], main = "ACF of fitted SARIMA(4,1,4)(1,0,0)[12] residual values")
pacf(q1bi_fit$resid[1:length(q1bi_fit$residuals)], main = "PACF of fitted SARIMA(4,1,4)(1,0,0)[12] residual values")
qqnorm(q1bi_fit$resid)
qqline(q1bi_fit$resid)
```

The residual values of SARIMA$(4, 1, 4)(1, 0, 0)_{12}$ model are centered at 0, have relatively constant variance. The variance is slightly larger between around 1950 through 1960 compared to the rest of the data and there are a few spikes, but they do not exhibit behaviors of autocorrelation since sequential terms do not usually have similar values based on the fluctuations. 

The ACF and PACF plots show that at lag 10 in both the plots, there is a noticeable spike in respective values, suggesting that the model fails to capture the seasonal cycle around this time. However, the the majority of the other lagged values beyond lag 0 of the residuals are approximately within or around the 95% error bars.

The Q-Q plot illustrates that the residuals follow an approximately normal distribution since the theoretical and sample quantiles are linearly related for the majority of the data; however, there are some minor deviations from normality at the tails.

The spikes in the ACF and PACF plots at the seasonal lag suggest that the residuals are not Gaussian white noise.

```{r q1b_1_sim}
par(mfrow=c(3,3))
plot(urate, ylab = 'Unemployment rate', main = 'Actual data')
for (i in 1:8){
  set.seed(i)
  plot(simulate(q1bi_fit),
     ylab = 'Unemployment rate',
     main = paste('Data from simulation', i, sep = ' '))
}
par(mfrow=c(1,1))
```

The behavior of the simulated values from the fitted model do not seem to mirror the sample data, since the simulated values do not capture the seasonal cycle present in the original unemployment rate data. Additionally, the simulated data does not appear to be sensible in the context of the problem since by definition the unemployment requires that the data be between 0 and 100 and is usually not greater than 10-20%. However, the simulations from this process show that the values of the data vary considerably by simulation and do not resemble the original data. For example, simulations 1, 3, 4, 6, and 8 are negative at some point during the simulation, while simulations 2, 5, and 7 have extremely percentages by the final year of the simulation. This does not strengthen the argument that the sample data could be from a SARIMA$(4, 1, 4)(1, 0, 0)_{12}$ process.

While the fitted values fit the sample observations well, the residuals do not display Gaussian white noise behavior and the simulated values are not similar to the sample observations, this suggests that the SARIMA$(4, 1, 4)(1, 0, 0)_{12}$ is not necessarily a good fit for the data.

#### ii)

```{r q1b_2}
auto.arima(urate, d =0, D = 1, trace = T, approximation = F, allowdrift = F)
```

The order of the parameters identified is SARIMA$(3, 0, 1)(0, 1, 1)_{12}$.

```{r q1b_2_obs_fit}
q1bii_fit <- Arima(urate, order = c(3,0,1), seasonal = list(order=c(0,1,1), period = 12))
plot(urate,
     main = "Observations vs. fitted SARIMA(3,0,1)(0,1,1)[12] values",
     ylab = "Unemployment rate")
lines(urate-q1bii_fit$resid, col="red")
legend("topleft",legend = c("Actual", "Fitted"), fill = c("black", "red"))
```

Comparing the observations to the fitted values, we see that the fitted values fit the data extremely well and capture almost all of the fluctuations in the sample. This suggests that the model is a good fit for the data.

```{r q1b_2_resid}
plot(q1bii_fit$resid, main = "Fitted SARIMA(3,0,1)(0,1,1)[12] residual values", ylab = "Residual values")
acf(q1bii_fit$resid[12:length(q1bii_fit$residuals)], main = "ACF of fitted SARIMA(3,0,1)(0,1,1)[12] residual values")
pacf(q1bii_fit$resid[12:length(q1bii_fit$residuals)], main = "PACF of fitted SARIMA(3,0,1)(0,1,1)[12] residual values")
qqnorm(q1bii_fit$resid)
qqline(q1bii_fit$resid)
```

The residual values of SARIMA$(3, 0, 1)(0, 1, 1)_{12}$ model are centered at 0, have relatively constant variance. The variance is slightly larger between around 1950 through 1960 compared to the rest of the data and there are a few spikes, but they do not exhibit behaviors of autocorrelation since sequential terms do not usually have similar values based on the fluctuations. 

The ACF and PACF plots show that all the lagged values beyond lag 0 of the residuals are approximately within the 95% error bars. 

The Q-Q plot illustrates that the residuals follow a normal distribution since the theoretical and sample quantiles are linearly related for the majority of the data; however, there are some minor deviations from normality at the tails. 

These suggest that the residuals are roughly Gaussian white noise.

```{r q1b_2_sim}
par(mfrow=c(3,3))
plot(urate, ylab = 'Unemployment rate', main = 'Actual data')
for (i in 1:8){
  set.seed(i)
  plot(simulate(q1bii_fit),
     ylab = 'Simulated u-rate',
     main = paste('Data from simulation', i, sep = ' '))
}
par(mfrow=c(1,1))
```

The behavior of the simulated values using the fitted model mirror the sample data in that they capture a seasonal cycle with a drift over time. Specifically, almost all the simulations have values that are sensible within the context of the data in that they are non-negative and fluctuate within historical patterns (i.e. do not exceed 10-20%). This strengthens the argument that the sample data could be from a SARIMA$(3, 0, 1)(0, 1, 1)_{12}$ process.

Given that the fitted values fit the sample observations reasonably well, the residuals display Gaussian white noise behavior, and the simulated values are similar to the sample observations, this implies that the SARIMA$(3, 0, 1)(0, 1, 1)_{12}$ is appropriate and a good fit for the data. Therefore, the SARIMA$(3, 0, 1)(0, 1, 1)_{12}$ model is a better fit for the data than the SARIMA$(4, 1, 4)(1, 0, 0)_{12}$ model.

### c)

```{r q1c, warning=FALSE, message=FALSE}
plot(forecast(q1bi_fit,h=36), ylab = "Unemployment rate", xlab = 'Time')
plot(forecast(q1bii_fit,h=36), ylab = "Unemployment rate", xlab = 'Time')
```

The mean forecast from the SARIMA$(4, 1, 4)(1, 0, 0)_{12}$ model is reasonable, but the lower and upper bounds of the forecast are very wide. The lower bound is less than 0, which is not sensible in the context of the problem. Additionally, based on the seasonal pattern in the data, it would probably not make sense for the data to continue trending downward and an increase (i.e. recession) could be expected.

The forecast from the SARIMA$(3, 0, 1)(0, 1, 1)_{12}$ model is reasonable in that the mean forecast is trending upwards and similar to historical data and the lower and upper bounds of the forecast are similar to historical patterns i.e. greater than 0  and less than 10. The model's prediction interval is also smaller implying less uncertainty. This better aligns with the context of the problem.

Based on the model validation from part b) and the forecasted values for the next 36 months, the SARIMA$(3, 0, 1)(0, 1, 1)_{12}$ with the seasonal difference provides a more trustworthy forecast.

## Question 2

```{r q2}
oni <- read.delim("oni.ascii_Dec_2021.txt", sep = "")
anom <- ts(oni$ANOM, start = 1950, frequency = 12)
```

### a)

```{r q2a_split_fit}
q2a_train <- window(anom, end = c(2015,12))
q2a_test <- window(anom, start = c(2016,1))
auto.arima(q2a_train, max.p = 5, max.q = 5, max.order = 10, stationary = T, seasonal = F, trace = T, stepwise = F, approximation = F)
```

For the full data, the model selected by auto.arima is the ARIMA(3,0,5). Looking at the data ending at December 2015, the model selected by auto.arima is ARIMA(4,0,5), so the same model is not identified compared to before.

```{r q2a_plot, warning=FALSE, message=FALSE}
q2a_fit <- arima(q2a_train, order = c(4,0,5), include.mean = F)
q2a_pred <- predict(q2a_fit, n.ahead = length(floor(window(time(q2a_test)))))
plot(anom, col = 'darkgray',ylab = 'Anomaly', main = 'Forecasts from model fit on data through December 2015')
lines(q2a_train)
lines(q2a_pred$pred, col = 'red')
lines(q2a_pred$pred - 1.96*q2a_pred$se, col = 'red')
lines(q2a_pred$pred + 1.96*q2a_pred$se, col = 'red')
```

The prediction interval for the ARIMA(4,0,5) model is sufficiently large to capture the true values of the anomalies, and the predicted expected value is roughly at the center of the data left out of training the model. However, we also see that after approximately 1 year (December 2016), the forecasts are constant for every time period going forward and therefore not very useful in forecasting future anomalies.

### b)

```{r q2b_split_fit}
q2b_train <- window(anom, end = c(2014,12))
q2b_test <- window(anom, start = c(2015,1))
auto.arima(q2b_train, max.p = 5, max.q = 5, max.order = 10, stationary = T, seasonal = F, trace = T, stepwise = F, approximation = F)
```

For the full data, the model selected by auto.arima is the ARIMA(3,0,5). Looking at the data ending at December 2014, the model selected by auto.arima is ARIMA(4,0,5), so the same model is not identified compared to before. 

```{r q2b_plot}
q2b_fit <- arima(q2b_train, order = c(4,0,5), include.mean = F)
q2b_pred <- predict(q2b_fit, n.ahead = length(floor(window(time(q2b_test)))))
plot(anom, col = 'darkgray', ylab = 'Anomaly',main = 'Forecasts from model fit on data through December 2014')
lines(q2b_train)
lines(q2b_pred$pred, col = 'red')
lines(q2b_pred$pred - 1.96*q2b_pred$se, col = 'red')
lines(q2b_pred$pred + 1.96*q2b_pred$se, col = 'red')
```

The prediction interval for the ARIMA(4,0,5) model fails to capture the large spike predicted in 2015. However, for the remainder of the data, the interval is large enough to capture true values of the anomalies, and the predicted expected value is roughly at the center of the data left out of training the model. We also see that after approximately 1 year (December 2015), the forecasts are constant for every time period going forward and therefore not very useful in forecasting future anomalies.

```{r q2b_sim_1}
n <- 3
par(mfrow=c(n,n))
for (i in 1:n^2){
  plot(anom, col = 'black',
     ylab = 'Anomaly',
     ylim = c(-3,3),
     main = paste('Data from simulation', i, sep = ' '))
  set.seed(i)
  lines(simulate(q2b_fit, future = T),
      xlim = range(floor(window(time(q2b_test)))),
      col = 'red')
}
mtext('Observations (black) vs. simulated (red) values',
      side = 3, line = -1, cex = 1.2,
      outer = T)
par(mfrow=c(1,1))
```

Based on the plot of the simulated data compared to the actual data, the model does not appear to successfully predict the anomaly in late 2015 for the majority of the simulations (only simulation 7 comes close to approximating this anomaly). This suggests that the model could not capture the anomaly and that it is likely an outlier. The model may also not be an appropriate fit for the data.

### c)

```{r q2c}
q2c <- arima(anom, order=c(3,0,5))
plot(forecast(q2c,h=24, level = 95), ylab = 'Anomaly', xlab = 'Time')
```

The best prediction of the ONI value at March 2022 is `r forecast(q2c,h=24,level=95)$mean %>% window(start = c(2022,3), end = c(2022,3)) %>% as.numeric()`, with a 95% predictive interval whose lower and upper bounds are `r forecast(q2c,h=24,level=95)$lower %>% window(start = c(2022,3), end = c(2022,3)) %>% as.numeric()` and `r forecast(q2c,h=24,level=95)$upper %>% window(start = c(2022,3), end = c(2022,3)) %>% as.numeric()`, respectively.

The best prediction of the ONI value at March 2023 is `r forecast(q2c,h=24,level=95)$mean %>% window(start = c(2023,3), end = c(2023,3)) %>% as.numeric()`, with a 95% predictive interval whose lower and upper bounds are `r forecast(q2c,h=24,level=95)$lower %>% window(start = c(2023,3), end = c(2023,3)) %>% as.numeric()` and `r forecast(q2c,h=24,level=95)$upper %>% window(start = c(2023,3), end = c(2023,3)) %>% as.numeric()`, respectively.

The mean prediction for the time period is roughly consistent with the historical data and around 0, while the prediction interval upper and lower bounds are with the historical data values as well. Therefore, the forecast is reasonable based on the data.

## Question 3

```{r q3_answer, cache=TRUE}
q3_sim_func <- function(use_anom = T){
  ifelse(use_anom, dat <- anom, dat <- simulate(q2c, future = F))
  x <- ((dat %>% as.vector()) >= 0.5) %>% rle()
  total <- (x$lengths[x$values] >= 5) %>% sum()
  total
}
anoms_oni <- q3_sim_func()
set.seed(1)
sim_vec <- replicate(10000, q3_sim_func(use_anom = F))

sim_vec %>%
  as.data.frame() %>%
  ggplot(aes(x = sim_vec)) +
  #geom_histogram(binwidth = 1) +
  geom_bar() +
  geom_vline(xintercept = sum(anoms_oni), linetype = 'dashed', color = 'red') +
  labs(x = 'Sum of simulated El Nino events', y = 'Frequency of sum of El Nino events',
       title = 'Histogram of El Nino events from 10000 ARIMA(3,0,5) simulations',
       subtitle = paste('Dotted line represents El Nino events from actual data:', sum(anoms_oni))) +
  theme_bw()
```

Using the 10000 simulations from the ARIMA(3,0,5) model, `r mean(sim_vec)` El Nino event events would occur on average from January 1950 to December 2021. `r sum(anoms_oni)` El Nino events were observed in the ONI time series, and this is roughly consistent with the model predictions since it shows up roughly in 1000 of the simulations and is close to the mean of the simulations. 

```{r timer, echo=FALSE, results='hide'}
# ptm <- proc.time()
# q3_sim_func <- function(dat = anom, use_anom = T){
#   ifelse(use_anom == T, dat <- anom, dat <- simulate(dat, future = F))
#   x <- rle((dat %>% as.vector()) >= 0.5)
#   total <- (x$lengths[x$values] >= 5) %>% sum()
#   total
# }
# anoms_oni <- q3_sim_func()
# set.seed(36618)
# sim_vec <- replicate(10000, q3_sim_func(dat = q2c, use_anom = F))
# proc.time() - ptm
# 
# ptm <- proc.time()
# q3_func <- function(dat = anom){
#   # defining the vectors and objects to be used for the loop
#   tmp <- NULL
#   tmp2 <- NULL
#   tmp3 <- NULL
#   flag <- NULL
#   tmp <- as.numeric(dat)
#   inner_vec <- c()
#   i <- 1
# 
#   while (i <= length(tmp)){
#   flag <- 0 # reset at top of loop
#   tmp2 <- tmp[i:length(tmp)] # subset data based on previously looked at obs
#   if (tmp2[1] >= 0.5){ # starting point to check if nino event
#     j <- 1
#     tmp3 <- c()
#     while (j <= length(tmp2)){ # check if succesive observations meet nino criteria
#       if (tmp2[j] >= 0.5){
#         tmp3 <- c(tmp3, tmp2[j]) #add to new vector
#         } else{
#           break
#           }
#       j <- j + 1
#       flag <- 1 # changed to signify that checking nino event happened
#     }
#   }
#   # append vector with value of 1 to signify nino event occurred
#   if (flag == 1 & length(tmp3) >= 5){
#     inner_vec <- c(inner_vec,1)
#   }
#   # update loop variable to skip if check for nino event occurred
#   # if it did, skip observations that were checked to avoid double counting
#   # if not, update loop variable by 1
#   ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#   }
#   # return result, will be a vector of 1s that can be summed for count of nino occurrences
#   inner_vec
# }
# anoms_oni <- q3_func()
# sim_vec <- rep(NA, 10000)
# set.seed(36618)
# for (k in 1:length(sim_vec)){
#   temp <- as.numeric(simulate(q2c, future = F))
#   sim_vec[k] <- sum(q3_func(dat = temp))
# }
# proc.time() - ptm
```
```{r q3_scratch, echo=FALSE, results='hide'}
# get_length = function(mod) {
#   
# my.sim = simulate(mod)
# test = rollapply(my.sim >= 0.5, 2, all, align = "left", fill = FALSE)
# rnums = as.vector(ifelse(test == FALSE, 0 , 1))
# runs = rle(rnums > 0)
# myruns = which(runs$values == TRUE & runs$lengths >= 5)
# length = length(myruns)
# return(length)
# }


  

## caleb stuff
# tibble(sim) %>% 
#   mutate(el_nino_1 =  ANOM >= 0.5 &
#                       lead(ANOM) >= 0.5 &
#                       lead(ANOM, 2) >= 0.5 &
#                       lead(ANOM, 3) >= 0.5 &
#                       lead(ANOM, 4) >= 0.5,
#          el_nino = el_nino_1 & !lag(el_nino_1)) %>% 
# 
# sim <- rep(NA, 10000)
# set.seed(36618)
# 
# data.frame(anom_sim = as.numeric(simulate(q2c, future = F))) %>% 
# # simulate(q2c, future = F) %>% as.numeric() %>% as.data.frame() %>%
# #   rename(anom_sim = .) %>%
#   mutate(thing = anom_sim >= 0.5 &
#            lead(anom_sim) >= 0.5 &
#            lead(anom_sim,2) >= 0.5 &
#            lead(anom_sim, 3) >=0.5 &
#            lead(anom_sim,4) >= 0.5,
#          el_nino = thing & (!lag(thing) | is.na(lag(thing)))) %>% 
#   summarise(x = sum(el_nino))
# 
# for (k in 1:length(sim)){
#   temp <- as.data.frame(simulate(q2c, future = F))
#   temp <- temp %>% mutate(
#     is_string_5_plus = . >= 0.5 &
#                       lead(.) >= 0.5 &
#                       lead(., 2) >= 0.5 &
#                       lead(., 3) >= 0.5 &
#                       lead(., 4) >= 0.5,
#     el_nino = is_string_5_plus & !lag(is_string_5_plus)) %>% 
#   summarise(sum(el_nino))
#   sim[k] <- sum(q3_func(dat = temp))
# }
# 
# tmp <- rep(NA, 1000)
# for (i in 1:1000){
#   set.seed(i)
#   data.frame(anom_sim = as.numeric(simulate(q2c, future = F))) %>% 
#     # simulate(q2c, future = F) %>% as.numeric() %>% as.data.frame() %>%
#     #   rename(anom_sim = .) %>%
#     mutate(thing = anom_sim >= 0.5 &
#                lead(anom_sim) >= 0.5 &
#                lead(anom_sim,2) >= 0.5 &
#                lead(anom_sim, 3) >=0.5 &
#                lead(anom_sim,4) >= 0.5,
#            el_nino = thing & (!lag(thing) | is.na(lag(thing))))
#   tmp <- ifelse()
# }

## my stuff

# 
# q3_func <- function(dat = anom){
#   tmp <- NULL
#   tmp2 <- NULL
#   tmp3 <- NULL
#   flag <- NULL
#   tmp <- as.numeric(dat)
#   inner_vec <- c()
#   i <- 1
#   while (i < length(tmp)){
#   flag <- 0
#   tmp2 <- tmp[i:length(tmp)]
#   if (tmp2[1] >= 0.5){
#     j <- 1
#     tmp3 <- c()
#     while (j < length(tmp2)){
#       if (tmp2[j] >= 0.5){
#         tmp3 <- c(tmp3, tmp2[j])
#         } else{
#           break
#           }
#       j <- j + 1
#       flag <- 1
#     }
#   }
#   if (flag == 1 & length(tmp3) >= 5){
#     inner_vec <- c(inner_vec,1)
#     }
#   ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#   }
#   inner_vec
# }
# 
# tmp <- NULL
# tmp2 <- NULL
# tmp3 <- NULL
# flag <- NULL
# tmp <- as.numeric(anom)
# anom_vec <- c()
# i <- 1
# while (i < length(tmp)){
# flag <- 0
# tmp2 <- tmp[i:length(tmp)]
# if (tmp2[1] >= 0.5){
#   j <- 1
#   tmp3 <- c()
#   while (j < length(tmp2)){
#     if (tmp2[j] >= 0.5){
#       tmp3 <- c(tmp3, tmp2[j])
#       } else{
#         break
#         }
#     j <- j + 1
#     flag <- 1
#   }
# }
# if (flag == 1 & length(tmp3) >= 5){
#   anom_vec <- c(anom_vec,1)
#   }
# ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
# }
# 
# tmp <- NULL
# tmp2 <- NULL
# tmp3 <- NULL
# flag <- NULL
# sim_vec <- rep(NA, 10000)
# for (k in 1:10000){
#   tmp <- as.numeric(simulate(q2c, future = F))
#   inner_sim_vec <- c()
#   i <- 1
#   while (i < length(tmp)){
#     flag <- 0
#     tmp2 <- tmp[i:length(tmp)]
#     if (tmp2[1] >= 0.5){
#       j <- 1
#       tmp3 <- c()
#       while (j < length(tmp2)){
#         if (tmp2[j] >= 0.5){
#           tmp3 <- c(tmp3, tmp2[j])
#           } else{
#             break
#             }
#         j <- j + 1
#         flag <- 1
#       }
#     }
#     if (flag == 1 & length(tmp3) >= 5){
#       inner_sim_vec <- c(inner_sim_vec,1)
#       }
#     ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#   }
#   sim_vec[k] <- sum(inner_sim_vec)
# }
# q3_func <- function(dat = anom){
#   tmp <- NULL
#   tmp2 <- NULL
#   tmp3 <- NULL
#   flag <- NULL
#   tmp <- as.numeric(dat)
#   inner_vec <- c()
#   i <- 1
#   while (i < length(tmp)){
#   flag <- 0
#   tmp2 <- tmp[i:length(tmp)]
#   if (tmp2[1] >= 0.5){
#     j <- 1
#     tmp3 <- c()
#     while (j < length(tmp2)){
#       if (tmp2[j] >= 0.5){
#         tmp3 <- c(tmp3, tmp2[j])
#         } else{
#           break
#           }
#       j <- j + 1
#       flag <- 1
#     }
#   }
#   if (flag == 1 & length(tmp3) >= 5){
#     inner_vec <- c(inner_vec,1)
#     }
#   ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#   }
#   inner_vec
# }
# x <- q3_func()
# 
# for (k in 1:length(sim_vec)){
#   tmp <- as.numeric(simulate(q2c, future = F))
#   inner_sim_vec <- c()
#   i <- 1
#   while (i < length(tmp)){
#     flag <- 0
#     tmp2 <- tmp[i:length(tmp)]
#     if (tmp2[1] >= 0.5){
#       j <- 1
#       tmp3 <- c()
#       while (j < length(tmp2)){
#         if (tmp2[j] >= 0.5){
#           tmp3 <- c(tmp3, tmp2[j])
#           } else{
#             break
#             }
#         j <- j + 1
#         flag <- 1
#       }
#     }
#     if (flag == 1 & length(tmp3) >= 5){
#       inner_sim_vec <- c(inner_sim_vec,1)
#       }
#     ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#   }
#   sim_vec[k] <- sum(inner_sim_vec)
# }
# 
# 
# set.seed(36618)
# q3_func <- function(dat = anom, sim = F){
#   tmp <- NULL
#   tmp2 <- NULL
#   tmp3 <- NULL
#   flag <- NULL
#   if (sim == F){
#     tmp <- as.numeric(dat)
#     anom_vec <- c()
#     i <- 1
#     while (i < length(tmp)){
#     flag <- 0
#     tmp2 <- tmp[i:length(tmp)]
#     if (tmp2[1] >= 0.5){
#       j <- 1
#       tmp3 <- c()
#       while (j < length(tmp2)){
#         if (tmp2[j] >= 0.5){
#           tmp3 <- c(tmp3, tmp2[j])
#           } else{
#             break
#             }
#         j <- j + 1
#         flag <- 1
#       }
#     }
#     if (flag == 1 & length(tmp3) >= 5){
#       anom_vec <- c(anom_vec,1)
#       }
#     ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#     }
#   }
#   
#   else{
#     sim_vec <- rep(NA, 10000)
#     for (k in 1:10000){
#       tmp <- as.numeric(dat)
#       inner_sim_vec <- c()
#       i <- 1
#       while (i < length(tmp)){
#         flag <- 0
#         tmp2 <- tmp[i:length(tmp)]
#         if (tmp2[1] >= 0.5){
#           j <- 1
#           tmp3 <- c()
#           while (j < length(tmp2)){
#             if (tmp2[j] >= 0.5){
#               tmp3 <- c(tmp3, tmp2[j])
#               } else{
#                 break
#                 }
#             j <- j + 1
#             flag <- 1
#           }
#         }
#         if (flag == 1 & length(tmp3) >= 5){
#           inner_sim_vec <- c(inner_sim_vec,1)
#           }
#         ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#       }
#       sim_vec[k] <- sum(inner_sim_vec)
#     }
#   }
#   x <- ifelse(sim == F, sum(anom_vec), sim_vec)
#   x
# }
# 
# tmp <- NULL
# tmp2 <- NULL
# tmp3 <- NULL
# flag <- NULL
# tmp <- as.numeric(dat)
# anom_vec <- c()
# i <- 1
# while (i < length(tmp)){
# flag <- 0
# tmp2 <- tmp[i:length(tmp)]
# if (tmp2[1] >= 0.5){
#   j <- 1
#   tmp3 <- c()
#   while (j < length(tmp2)){
#     if (tmp2[j] >= 0.5){
#       tmp3 <- c(tmp3, tmp2[j])
#       } else{
#         break
#         }
#     j <- j + 1
#     flag <- 1
#   }
# }
# if (flag == 1 & length(tmp3) >= 5){
#   anom_vec <- c(anom_vec,1)
#   }
# ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
# }
# 
# tmp <- NULL
# tmp2 <- NULL
# tmp3 <- NULL
# flag <- NULL
# sim_vec <- rep(NA, 10000)
# for (k in 1:10000){
#   tmp <- as.numeric(simulate(q2c, future = F))
#   inner_sim_vec <- c()
#   i <- 1
#   while (i < length(tmp)){
#     flag <- 0
#     tmp2 <- tmp[i:length(tmp)]
#     if (tmp2[1] >= 0.5){
#       j <- 1
#       tmp3 <- c()
#       while (j < length(tmp2)){
#         if (tmp2[j] >= 0.5){
#           tmp3 <- c(tmp3, tmp2[j])
#           } else{
#             break
#             }
#         j <- j + 1
#         flag <- 1
#       }
#     }
#     if (flag == 1 & length(tmp3) >= 5){
#       inner_sim_vec <- c(inner_sim_vec,1)
#       }
#     ifelse(flag == 0, i <- i + 1, i <- i + length(tmp3))
#   }
#   sim_vec[k] <- sum(inner_sim_vec)
# }

```